{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Company Name Standardization\n",
        "\n",
        "## Objective\n",
        "Standardize company names to consolidate variations and improve data quality for analysis.\n",
        "\n",
        "## Tasks\n",
        "- Identify company name variations (case, suffixes, subsidiaries)\n",
        "- Create comprehensive company mapping dictionary\n",
        "- Apply standardization rules systematically\n",
        "- Verify consolidation results\n",
        "- Handle edge cases (typos, abbreviations, subsidiaries)\n",
        "\n",
        "## Expected Output\n",
        "- Standardized company names in new column: `company_clean`\n",
        "- Reduced unique company count (1,908 ‚Üí ~1,700-1,800)\n",
        "- Mapping documentation for transparency\n",
        "- Updated dataset: `data/processed/jobs_cleaned_with_std_companies.csv`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "from difflib import SequenceMatcher\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "print(\" Libraries imported successfully\")\n",
        "print(f\"   Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Cleaned Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\" Loading cleaned dataset...\\n\")\n",
        "\n",
        "df = pd.read_csv('data/processed/jobs_cleaned.csv')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\" DATASET LOADED\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n Dataset Overview:\")\n",
        "print(f\"   Total records: {len(df):,}\")\n",
        "print(f\"   Unique companies: {df['company'].nunique():,}\")\n",
        "print(f\"   Date range: {df['posting_date'].min()} to {df['posting_date'].max()}\")\n",
        "\n",
        "print(f\"\\nüè¢ Top 15 Companies (current):\")\n",
        "top_15 = df['company'].value_counts().head(15)\n",
        "for idx, (company, count) in enumerate(top_15.items(), 1):\n",
        "    print(f\"   {idx:2d}. {company[:45]:<45} {count:>4} jobs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Analyze Company Name Patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_company_patterns(df):\n",
        "    \"\"\"Analyze company name patterns and identify variations\"\"\"\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    print(\" COMPANY NAME PATTERN ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Case sensitivity analysis\n",
        "    print(\"\\n1Ô∏è‚É£  Case Sensitivity Issues:\")\n",
        "    company_normalized = {}\n",
        "    for company in df['company'].unique():\n",
        "        lower = company.lower()\n",
        "        if lower not in company_normalized:\n",
        "            company_normalized[lower] = []\n",
        "        company_normalized[lower].append(company)\n",
        "    \n",
        "    case_issues = {k: v for k, v in company_normalized.items() if len(v) > 1}\n",
        "    print(f\"   Found {len(case_issues)} companies with case variations\")\n",
        "    \n",
        "    case_mappings = {}\n",
        "    for lower_name, variations in case_issues.items():\n",
        "        counts = [(v, (df['company'] == v).sum()) for v in variations]\n",
        "        primary = max(counts, key=lambda x: x[1])[0]\n",
        "        for var, _ in counts:\n",
        "            if var != primary:\n",
        "                case_mappings[var] = primary\n",
        "    \n",
        "    print(f\"   Will consolidate {len(case_mappings)} variations\")\n",
        "    \n",
        "    # Suffix analysis\n",
        "    print(\"\\n2Ô∏è‚É£  Legal Suffix Variations:\")\n",
        "    suffix_patterns = [\n",
        "        r',?\\s+(LLC|Inc\\.?|Corp\\.?|Corporation|Ltd\\.?|Limited|LLP|LP)$',\n",
        "        r',?\\s+(Co\\.?|Company|PLC|GmbH|SA|AG)$'\n",
        "    ]\n",
        "    \n",
        "    companies_with_suffixes = 0\n",
        "    for company in df['company'].unique():\n",
        "        for pattern in suffix_patterns:\n",
        "            if re.search(pattern, company, re.IGNORECASE):\n",
        "                companies_with_suffixes += 1\n",
        "                break\n",
        "    \n",
        "    print(f\"   Companies with legal suffixes: {companies_with_suffixes}\")\n",
        "    \n",
        "    # Major tech company variations\n",
        "    print(\"\\n3Ô∏è‚É£  Major Tech Company Variations:\")\n",
        "    tech_checks = {\n",
        "        'Amazon': ['amazon'],\n",
        "        'Microsoft': ['microsoft'],\n",
        "        'Google': ['google', 'alphabet'],\n",
        "        'Meta': ['meta', 'facebook'],\n",
        "        'Apple': ['apple'],\n",
        "        'Oracle': ['oracle'],\n",
        "        'IBM': ['ibm'],\n",
        "        'Adobe': ['adobe'],\n",
        "        'NVIDIA': ['nvidia'],\n",
        "    }\n",
        "    \n",
        "    tech_variations = {}\n",
        "    for tech_name, keywords in tech_checks.items():\n",
        "        matches = []\n",
        "        for company in df['company'].unique():\n",
        "            company_lower = company.lower()\n",
        "            # Exact or starts with tech name\n",
        "            if any(company_lower == kw or company_lower.startswith(kw + ' ') for kw in keywords):\n",
        "                count = (df['company'] == company).sum()\n",
        "                matches.append((company, count))\n",
        "        \n",
        "        if len(matches) > 1:\n",
        "            tech_variations[tech_name] = matches\n",
        "            total = sum(c for _, c in matches)\n",
        "            print(f\"   {tech_name}: {total} jobs across {len(matches)} variations\")\n",
        "            for company, count in sorted(matches, key=lambda x: -x[1])[:3]:\n",
        "                print(f\"      ‚Üí {company[:50]:<50} {count:>3} jobs\")\n",
        "    \n",
        "    return case_mappings, tech_variations\n",
        "\n",
        "case_mappings, tech_variations = analyze_company_patterns(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build Standardization Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_legal_suffixes(company_name):\n",
        "    \"\"\"Remove common legal suffixes from company names\"\"\"\n",
        "    if pd.isna(company_name):\n",
        "        return company_name\n",
        "    \n",
        "    suffixes = [\n",
        "        r',?\\s+LLC$',\n",
        "        r',?\\s+Inc\\.?$',\n",
        "        r',?\\s+Corp\\.?$',\n",
        "        r',?\\s+Corporation$',\n",
        "        r',?\\s+Ltd\\.?$',\n",
        "        r',?\\s+Limited$',\n",
        "        r',?\\s+LLP$',\n",
        "        r',?\\s+LP$',\n",
        "        r',?\\s+Co\\.?$',\n",
        "        r',?\\s+Company$',\n",
        "        r',?\\s+PLC$',\n",
        "        r',?\\s+GmbH$',\n",
        "        r',?\\s+SA$',\n",
        "        r',?\\s+AG$',\n",
        "    ]\n",
        "    \n",
        "    cleaned = company_name\n",
        "    for pattern in suffixes:\n",
        "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
        "    \n",
        "    cleaned = cleaned.strip().strip(',').strip()\n",
        "    \n",
        "    return cleaned if cleaned else company_name\n",
        "\n",
        "\n",
        "def standardize_spacing(company_name):\n",
        "    \"\"\"Normalize spacing in company names\"\"\"\n",
        "    if pd.isna(company_name):\n",
        "        return company_name\n",
        "    \n",
        "    cleaned = re.sub(r'\\s+', ' ', company_name)\n",
        "    \n",
        "    cleaned = cleaned.strip()\n",
        "    \n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def apply_title_case(company_name):\n",
        "    \"\"\"Apply intelligent title casing\"\"\"\n",
        "    if pd.isna(company_name):\n",
        "        return company_name\n",
        "    \n",
        "    keep_upper = ['IBM', 'JPMorgan', 'CVS', 'BMW', 'AWS', 'NASA', \n",
        "                  'FBI', 'CIA', 'NFL', 'NBA', 'NVIDIA', 'AMD']\n",
        "    \n",
        "    for term in keep_upper:\n",
        "        if company_name.upper() == term.upper():\n",
        "            return term\n",
        "    \n",
        "    exceptions = ['and', 'of', 'the', 'for', 'in', 'on', 'at', 'to', 'a', 'an']\n",
        "    \n",
        "    words = company_name.split()\n",
        "    result = []\n",
        "    \n",
        "    for i, word in enumerate(words):\n",
        "        if word.upper() in keep_upper:\n",
        "            result.append(word.upper())\n",
        "        elif i > 0 and word.lower() in exceptions:\n",
        "            result.append(word.lower())\n",
        "        else:\n",
        "            result.append(word.capitalize())\n",
        "    \n",
        "    return ' '.join(result)\n",
        "\n",
        "\n",
        "print(\" Standardization functions defined:\")\n",
        "print(\"   ‚Ä¢ remove_legal_suffixes()\")\n",
        "print(\"   ‚Ä¢ standardize_spacing()\")\n",
        "print(\"   ‚Ä¢ apply_title_case()\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Company Mapping Dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üó∫Ô∏è  Building comprehensive company mapping dictionary...\\n\")\n",
        "\n",
        "company_mapping = {}\n",
        "\n",
        "# 1. Tech Giants and Subsidiaries\n",
        "tech_mapping = {\n",
        "    # Amazon\n",
        "    'Amazon Stores': 'Amazon',\n",
        "    'Amazon Development Center U.S., Inc.': 'Amazon',\n",
        "    'Amazon Web Services, Inc.': 'Amazon',\n",
        "    'Amazon Web Services': 'Amazon',\n",
        "    'AWS': 'Amazon',\n",
        "    \n",
        "    # Microsoft\n",
        "    'Microsoft Corporation': 'Microsoft',\n",
        "    'MSFT': 'Microsoft',\n",
        "    \n",
        "    # Google/Alphabet\n",
        "    'Alphabet Inc.': 'Google',\n",
        "    'Alphabet': 'Google',\n",
        "    'Google LLC': 'Google',\n",
        "    \n",
        "    # Meta/Facebook\n",
        "    'Facebook': 'Meta',\n",
        "    'Meta Platforms': 'Meta',\n",
        "    'Meta Platforms, Inc.': 'Meta',\n",
        "    'Meta Reality Labs': 'Meta',\n",
        "    'Meta Reality Labs - Conversational AI': 'Meta',\n",
        "    \n",
        "    # Apple\n",
        "    'Apple Inc.': 'Apple',\n",
        "    'Apple Computer': 'Apple',\n",
        "    \n",
        "    # Oracle\n",
        "    'Oracle Corporation': 'Oracle',\n",
        "    \n",
        "    # Adobe\n",
        "    'Adobe Inc.': 'Adobe',\n",
        "    'Adobe Systems': 'Adobe',\n",
        "    \n",
        "    # Salesforce\n",
        "    'Salesforce.com': 'Salesforce',\n",
        "    \n",
        "    # IBM\n",
        "    'International Business Machines': 'IBM',\n",
        "    \n",
        "    # Intel\n",
        "    'Intel Corporation': 'Intel',\n",
        "    \n",
        "    # NVIDIA\n",
        "    'NVIDIA Corporation': 'NVIDIA',\n",
        "    'Nvidia': 'NVIDIA',\n",
        "    \n",
        "    # Tesla\n",
        "    'Tesla Motors': 'Tesla',\n",
        "    'Tesla Inc.': 'Tesla',\n",
        "    \n",
        "    # Netflix\n",
        "    'Netflix Inc.': 'Netflix',\n",
        "    \n",
        "    # Uber\n",
        "    'Uber Technologies': 'Uber',\n",
        "    'Uber Technologies, Inc.': 'Uber',\n",
        "}\n",
        "\n",
        "company_mapping.update(tech_mapping)\n",
        "\n",
        "# 2. Consulting Firms\n",
        "consulting_mapping = {\n",
        "    'Deloitte Consulting': 'Deloitte',\n",
        "    'Deloitte LLP': 'Deloitte',\n",
        "    'DELOITTE': 'Deloitte',\n",
        "    'Deloitte & Touche': 'Deloitte',\n",
        "    \n",
        "    'Accenture Federal Services': 'Accenture',\n",
        "    'Accenture LLP': 'Accenture',\n",
        "    \n",
        "    'Boston Consulting Group (BCG)': 'Boston Consulting Group',\n",
        "    'BCG': 'Boston Consulting Group',\n",
        "    \n",
        "    'McKinsey & Company': 'McKinsey',\n",
        "    'McKinsey': 'McKinsey',\n",
        "    \n",
        "    'PwC': 'PricewaterhouseCoopers',\n",
        "    'PricewaterhouseCoopers LLP': 'PricewaterhouseCoopers',\n",
        "    \n",
        "    'EY': 'Ernst & Young',\n",
        "    'Ernst & Young LLP': 'Ernst & Young',\n",
        "    \n",
        "    'KPMG LLP': 'KPMG',\n",
        "}\n",
        "\n",
        "company_mapping.update(consulting_mapping)\n",
        "\n",
        "# 3. Aerospace & Defense\n",
        "aerospace_mapping = {\n",
        "    'Boeing Company': 'Boeing',\n",
        "    'BOEING': 'Boeing',\n",
        "    'The Boeing Company': 'Boeing',\n",
        "    \n",
        "    'Lockheed Martin Corporation': 'Lockheed Martin',\n",
        "    'Lockheed Martin Corp.': 'Lockheed Martin',\n",
        "    \n",
        "    'Raytheon Technologies': 'RTX',\n",
        "    'RTX Corporation': 'RTX',\n",
        "    'Raytheon': 'RTX',\n",
        "    \n",
        "    'Northrop Grumman Corporation': 'Northrop Grumman',\n",
        "    \n",
        "    'General Dynamics Corporation': 'General Dynamics',\n",
        "}\n",
        "\n",
        "company_mapping.update(aerospace_mapping)\n",
        "\n",
        "# 4. Healthcare\n",
        "healthcare_mapping = {\n",
        "    'CVS HEALTH': 'CVS Health',\n",
        "    'CVS Pharmacy': 'CVS Health',\n",
        "    'CVS': 'CVS Health',\n",
        "    \n",
        "    'UnitedHealth Group': 'UnitedHealth',\n",
        "    'United Healthcare': 'UnitedHealth',\n",
        "    \n",
        "    'Kaiser Permanente': 'Kaiser',\n",
        "    'Kaiser Foundation': 'Kaiser',\n",
        "}\n",
        "\n",
        "company_mapping.update(healthcare_mapping)\n",
        "\n",
        "# 5. Financial Services\n",
        "finance_mapping = {\n",
        "    'JPMorganChase': 'JPMorgan Chase',\n",
        "    'JPMorgan Chase & Co.': 'JPMorgan Chase',\n",
        "    'JP Morgan': 'JPMorgan Chase',\n",
        "    'Chase': 'JPMorgan Chase',\n",
        "    \n",
        "    'Bank of America Corporation': 'Bank of America',\n",
        "    'BofA': 'Bank of America',\n",
        "    \n",
        "    'Goldman Sachs Group': 'Goldman Sachs',\n",
        "    'Goldman Sachs & Co.': 'Goldman Sachs',\n",
        "    \n",
        "    'Morgan Stanley & Co.': 'Morgan Stanley',\n",
        "    \n",
        "    'Wells Fargo & Company': 'Wells Fargo',\n",
        "    'Wells Fargo Bank': 'Wells Fargo',\n",
        "}\n",
        "\n",
        "company_mapping.update(finance_mapping)\n",
        "\n",
        "# 6. Automotive\n",
        "auto_mapping = {\n",
        "    'General Motors Company': 'General Motors',\n",
        "    'GM': 'General Motors',\n",
        "    \n",
        "    'Ford Motor Company': 'Ford',\n",
        "    'Ford Motor': 'Ford',\n",
        "}\n",
        "\n",
        "company_mapping.update(auto_mapping)\n",
        "\n",
        "# 7. Telecommunications\n",
        "telecom_mapping = {\n",
        "    'AT&T Inc.': 'AT&T',\n",
        "    'ATT': 'AT&T',\n",
        "    \n",
        "    'Verizon Communications': 'Verizon',\n",
        "    'Verizon Wireless': 'Verizon',\n",
        "    \n",
        "    'T-Mobile USA': 'T-Mobile',\n",
        "    'TMobile': 'T-Mobile',\n",
        "}\n",
        "\n",
        "company_mapping.update(telecom_mapping)\n",
        "\n",
        "# 8. Retail\n",
        "retail_mapping = {\n",
        "    'Walmart Inc.': 'Walmart',\n",
        "    'Wal-Mart': 'Walmart',\n",
        "    \n",
        "    'Target Corporation': 'Target',\n",
        "}\n",
        "\n",
        "company_mapping.update(retail_mapping)\n",
        "\n",
        "# Add case-based mappings (from analysis)\n",
        "company_mapping.update(case_mappings)\n",
        "\n",
        "print(f\" Company mapping dictionary created\")\n",
        "print(f\"   Total mappings: {len(company_mapping)}\")\n",
        "print(f\"\\n   Categories:\")\n",
        "print(f\"      ‚Ä¢ Tech giants & subsidiaries: {len(tech_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Consulting firms: {len(consulting_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Aerospace & defense: {len(aerospace_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Healthcare: {len(healthcare_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Financial services: {len(finance_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Automotive: {len(auto_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Telecommunications: {len(telecom_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Retail: {len(retail_mapping)}\")\n",
        "print(f\"      ‚Ä¢ Case sensitivity fixes: {len(case_mappings)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardize_company_name(company_name):\n",
        "    \"\"\"\n",
        "    Apply full standardization pipeline to a company name\n",
        "    \n",
        "    Steps:\n",
        "    1. Apply explicit mapping (if exists)\n",
        "    2. Standardize spacing\n",
        "    3. Remove legal suffixes\n",
        "    4. Apply title casing\n",
        "    \"\"\"\n",
        "    if pd.isna(company_name):\n",
        "        return company_name\n",
        "    \n",
        "    # Step 1: Check if we have an explicit mapping\n",
        "    if company_name in company_mapping:\n",
        "        return company_mapping[company_name]\n",
        "    \n",
        "    # Step 2: Standardize spacing\n",
        "    cleaned = standardize_spacing(company_name)\n",
        "    \n",
        "    # Step 3: Remove legal suffixes\n",
        "    cleaned = remove_legal_suffixes(cleaned)\n",
        "    \n",
        "    # Step 4: Apply title casing\n",
        "    cleaned = apply_title_case(cleaned)\n",
        "    \n",
        "    # Check mapping again after cleaning\n",
        "    if cleaned in company_mapping:\n",
        "        return company_mapping[cleaned]\n",
        "    \n",
        "    return cleaned\n",
        "\n",
        "\n",
        "print(\"üîÑ Applying standardization pipeline...\\n\")\n",
        "\n",
        "# Create the cleaned company column\n",
        "df['company_clean'] = df['company'].apply(standardize_company_name)\n",
        "\n",
        "print(\" Standardization complete!\")\n",
        "print(f\"\\n   Original unique companies: {df['company'].nunique():,}\")\n",
        "print(f\"   Standardized unique companies: {df['company_clean'].nunique():,}\")\n",
        "print(f\"   Reduction: {df['company'].nunique() - df['company_clean'].nunique():,} companies consolidated\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Verification & Quality Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\" STANDARDIZATION VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check 1: Compare top companies before/after\n",
        "print(\"\\n1Ô∏è‚É£  Top 15 Companies Comparison:\")\n",
        "print(\"\\n   BEFORE standardization:\")\n",
        "top_before = df['company'].value_counts().head(15)\n",
        "for idx, (company, count) in enumerate(top_before.items(), 1):\n",
        "    print(f\"   {idx:2d}. {company[:45]:<45} {count:>4} jobs\")\n",
        "\n",
        "print(\"\\n   AFTER standardization:\")\n",
        "top_after = df['company_clean'].value_counts().head(15)\n",
        "for idx, (company, count) in enumerate(top_after.items(), 1):\n",
        "    print(f\"   {idx:2d}. {company[:45]:<45} {count:>4} jobs\")\n",
        "\n",
        "# Check 2: Show specific consolidations\n",
        "print(\"\\n\\n2Ô∏è‚É£  Specific Consolidation Examples:\")\n",
        "\n",
        "examples = [\n",
        "    'Boeing',\n",
        "    'Deloitte', \n",
        "    'Microsoft',\n",
        "    'Amazon',\n",
        "    'Meta',\n",
        "    'CVS Health',\n",
        "]\n",
        "\n",
        "for company in examples:\n",
        "    before_variations = df[df['company_clean'] == company]['company'].unique()\n",
        "    after_count = (df['company_clean'] == company).sum()\n",
        "    \n",
        "    if len(before_variations) > 1:\n",
        "        print(f\"\\n   {company}:\")\n",
        "        print(f\"      Total jobs: {after_count}\")\n",
        "        print(f\"      Consolidated from {len(before_variations)} variations:\")\n",
        "        for var in sorted(before_variations):\n",
        "            count = (df['company'] == var).sum()\n",
        "            print(f\"         ‚Ä¢ {var[:50]:<50} ({count} jobs)\")\n",
        "\n",
        "# Check 3: Verify no data loss\n",
        "print(\"\\n\\n3Ô∏è‚É£  Data Integrity Check:\")\n",
        "null_before = df['company'].isnull().sum()\n",
        "null_after = df['company_clean'].isnull().sum()\n",
        "print(f\"   Null values before: {null_before}\")\n",
        "print(f\"   Null values after: {null_after}\")\n",
        "print(f\"    No data loss\" if null_before == null_after else \"   ‚ö†Ô∏è  Data loss detected!\")\n",
        "\n",
        "# Check 4: Suffix removal effectiveness\n",
        "print(\"\\n4Ô∏è‚É£  Suffix Removal Effectiveness:\")\n",
        "suffixes_before = df['company'].str.contains(r'(LLC|Inc\\.?|Corp\\.?|Corporation|Ltd\\.?)$', \n",
        "                                              case=False, na=False, regex=True).sum()\n",
        "suffixes_after = df['company_clean'].str.contains(r'(LLC|Inc\\.?|Corp\\.?|Corporation|Ltd\\.?)$',\n",
        "                                                   case=False, na=False, regex=True).sum()\n",
        "print(f\"   Companies with suffixes before: {suffixes_before}\")\n",
        "print(f\"   Companies with suffixes after: {suffixes_after}\")\n",
        "print(f\"   Suffixes removed: {suffixes_before - suffixes_after}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Edge Case Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\" EDGE CASE ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find potential issues or missed consolidations\n",
        "print(\"\\n1Ô∏è‚É£  Companies with Very Similar Names (Potential Missed Matches):\")\n",
        "\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_similar_companies(companies, threshold=0.85):\n",
        "    \"\"\"Find pairs of companies with similar names\"\"\"\n",
        "    similar_pairs = []\n",
        "    company_list = companies.tolist()\n",
        "    \n",
        "    for i in range(len(company_list)):\n",
        "        for j in range(i + 1, len(company_list)):\n",
        "            if SequenceMatcher(None, company_list[i].lower(), \n",
        "                             company_list[j].lower()).ratio() > threshold:\n",
        "                count_i = (companies == company_list[i]).sum()\n",
        "                count_j = (companies == company_list[j]).sum()\n",
        "                if count_i > 1 or count_j > 1:  # Only show if significant\n",
        "                    similar_pairs.append((company_list[i], company_list[j], count_i, count_j))\n",
        "    \n",
        "    return similar_pairs\n",
        "\n",
        "print(\"   Checking for similar company names (>85% similarity)...\")\n",
        "similar = find_similar_companies(df['company_clean'].value_counts().head(100).index, threshold=0.85)\n",
        "\n",
        "if similar:\n",
        "    print(f\"   Found {len(similar)} potential matches to review:\\n\")\n",
        "    for comp1, comp2, count1, count2 in similar[:10]:\n",
        "        print(f\"      ‚Ä¢ {comp1[:40]:<40} ({count1} jobs)\")\n",
        "        print(f\"        vs {comp2[:40]:<40} ({count2} jobs)\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"    No obvious similar names detected\")\n",
        "\n",
        "# Check for extremely short names (might be abbreviations)\n",
        "print(\"\\n2Ô∏è‚É£  Very Short Company Names (Potential Abbreviations):\")\n",
        "short_names = df[df['company_clean'].str.len() <= 4]['company_clean'].value_counts().head(10)\n",
        "if len(short_names) > 0:\n",
        "    print(\"   Companies with ‚â§4 characters:\")\n",
        "    for company, count in short_names.items():\n",
        "        print(f\"      ‚Ä¢ {company:<10} ({count} jobs)\")\n",
        "else:\n",
        "    print(\"    No concerning short names found\")\n",
        "\n",
        "# Check for \"Not specified\"\n",
        "print(\"\\n3Ô∏è‚É£  Missing/Invalid Company Names:\")\n",
        "not_specified = (df['company_clean'] == 'Not specified').sum()\n",
        "print(f\"   'Not specified': {not_specified} jobs\")\n",
        "if not_specified > 0:\n",
        "    print(f\"   ({not_specified/len(df)*100:.2f}% of dataset)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Generate Mapping Documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\" Generating mapping documentation...\\n\")\n",
        "\n",
        "# Create a comprehensive mapping log\n",
        "mapping_log = []\n",
        "\n",
        "for original, cleaned in zip(df['company'], df['company_clean']):\n",
        "    if original != cleaned:\n",
        "        mapping_log.append({\n",
        "            'original': original,\n",
        "            'standardized': cleaned,\n",
        "            'transformation': 'explicit_mapping' if original in company_mapping else 'automated_cleaning'\n",
        "        })\n",
        "\n",
        "mapping_df = pd.DataFrame(mapping_log)\n",
        "\n",
        "if len(mapping_df) > 0:\n",
        "    mapping_df = mapping_df.drop_duplicates()\n",
        "    mapping_summary = mapping_df.groupby('standardized')['original'].apply(list).reset_index()\n",
        "    mapping_summary.columns = ['Standardized_Name', 'Original_Variations']\n",
        "    mapping_summary['Variation_Count'] = mapping_summary['Original_Variations'].apply(len)\n",
        "    mapping_summary = mapping_summary.sort_values('Variation_Count', ascending=False)\n",
        "    \n",
        "    # Save mapping documentation\n",
        "    mapping_summary.to_csv('data/processed/company_name_mappings.csv', index=False)\n",
        "    \n",
        "    print(f\" Mapping documentation saved\")\n",
        "    print(f\"   File: data/processed/company_name_mappings.csv\")\n",
        "    print(f\"   Total mappings: {len(mapping_df)}\")\n",
        "    print(f\"   Unique transformations: {len(mapping_summary)}\")\n",
        "    \n",
        "    print(f\"\\n Top 10 Companies with Most Variations:\")\n",
        "    for idx, row in mapping_summary.head(10).iterrows():\n",
        "        print(f\"\\n   {row['Standardized_Name']} ({row['Variation_Count']} variations):\")\n",
        "        for var in row['Original_Variations'][:5]:\n",
        "            print(f\"      ‚Ä¢ {var}\")\n",
        "        if row['Variation_Count'] > 5:\n",
        "            print(f\"      ... and {row['Variation_Count'] - 5} more\")\n",
        "else:\n",
        "    print(\"   ‚ÑπÔ∏è  No mappings to document (all names were already standardized)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Save Standardized Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "output_file = 'data/processed/jobs_with_standardized_companies.csv'\n",
        "\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\" STANDARDIZED DATASET SAVED\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n   File: {output_file}\")\n",
        "print(f\"   Size: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB\")\n",
        "print(f\"   Records: {len(df):,}\")\n",
        "print(f\"   Columns: {len(df.columns)}\")\n",
        "print(f\"\\n   New column added: 'company_clean'\")\n",
        "\n",
        "print(f\"\\n Phase 2.2 Complete: Company Name Standardization\")\n",
        "print(f\"\\n   Dataset ready for exploratory data analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Final Summary & Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" COMPANY STANDARDIZATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n1Ô∏è  Overall Impact:\")\n",
        "print(f\"   Original unique companies: {df['company'].nunique():,}\")\n",
        "print(f\"   Standardized unique companies: {df['company_clean'].nunique():,}\")\n",
        "reduction = df['company'].nunique() - df['company_clean'].nunique()\n",
        "reduction_pct = (reduction / df['company'].nunique()) * 100\n",
        "print(f\"   Companies consolidated: {reduction:,} ({reduction_pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\n2Ô∏è  Standardization Methods Applied:\")\n",
        "print(f\"   ‚Ä¢ Explicit mappings: {len(company_mapping)} rules\")\n",
        "print(f\"   ‚Ä¢ Legal suffix removal\")\n",
        "print(f\"   ‚Ä¢ Case standardization\")\n",
        "print(f\"   ‚Ä¢ Spacing normalization\")\n",
        "\n",
        "print(f\"\\n3Ô∏è Top 20 Companies (After Standardization):\")\n",
        "top_20_final = df['company_clean'].value_counts().head(20)\n",
        "for idx, (company, count) in enumerate(top_20_final.items(), 1):\n",
        "    pct = (count / len(df)) * 100\n",
        "    print(f\"   {idx:2d}. {company[:40]:<40} {count:>4} jobs ({pct:>5.2f}%)\")\n",
        "\n",
        "print(f\"\\n4Ô∏è  Data Quality Metrics:\")\n",
        "print(f\"   Total records: {len(df):,}\")\n",
        "print(f\"   Records with valid companies: {(df['company_clean'] != 'Not specified').sum():,}\")\n",
        "print(f\"   Data completeness: {(df['company_clean'] != 'Not specified').sum()/len(df)*100:.1f}%\")\n",
        "\n",
        "print(f\"\\n5Ô∏è  Industry Representation (Top Companies):\")\n",
        "# Categorize top companies by rough industry\n",
        "industries = {\n",
        "    'Tech': ['Oracle', 'Microsoft', 'Amazon', 'Google', 'Meta', 'Apple', 'NVIDIA', 'Adobe', 'Salesforce'],\n",
        "    'Consulting': ['Deloitte', 'Accenture', 'Boston Consulting Group', 'McKinsey', 'PricewaterhouseCoopers'],\n",
        "    'Aerospace': ['Boeing', 'Lockheed Martin', 'RTX', 'Northrop Grumman'],\n",
        "    'Healthcare': ['CVS Health', 'Molina Healthcare', 'Intermountain Health', 'Highmark Health'],\n",
        "    'Finance': ['JPMorgan Chase', 'Bank of America', 'Goldman Sachs', 'Morgan Stanley']\n",
        "}\n",
        "\n",
        "for industry, companies in industries.items():\n",
        "    count = df[df['company_clean'].isin(companies)].shape[0]\n",
        "    if count > 0:\n",
        "        pct = (count / len(df)) * 100\n",
        "        print(f\"   {industry}: {count:,} jobs ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" COMPANY NAME STANDARDIZATION COMPLETE\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n Sample of standardized data:\\n\")\n",
        "sample_cols = ['company', 'company_clean', 'role', 'location', 'has_ai_keywords', 'source']\n",
        "df[sample_cols].head(15)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
