{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Adzuna API Data Collection\n",
    "\n",
    "## Objective\n",
    "Collect tech job postings from Adzuna API (2023-2024) to enhance our HackerNews dataset.\n",
    "\n",
    "\n",
    "## Expected Output\n",
    "- 2,000-5,000 tech job postings\n",
    "- Focus: AI, ML, Software Engineering roles\n",
    "- Time period: 2023-2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:23:43.867697Z",
     "start_time": "2025-10-24T17:23:43.477984Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import re\n",
    "\n",
    "print(\" Libraries imported successfully\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:24:44.789501Z",
     "start_time": "2025-10-24T17:24:44.785369Z"
    }
   },
   "source": [
    "# API Configuration, # I know this is not a good practice, but I don't want to pay for a API key, it's just for a project and a free tier api so no big deal, could use .env file if needed and inhance the project further\n",
    "APP_ID = '4ad8a509'\n",
    "APP_KEY = '01485b2cbeba2ea07f3ed7182a919f2f'\n",
    "BASE_URL = 'https://api.adzuna.com/v1/api/jobs/us/search'\n",
    "\n",
    "# Rate Limiting (Adzuna limits: 25/min, 250/day)\n",
    "REQUEST_DELAY = 5  # seconds between requests (safe: 12 requests/min)\n",
    "RESULTS_PER_PAGE = 50  # max 50 per Adzuna docs\n",
    "MAX_PAGES = 100  # collect up to 5,000 jobs\n",
    "\n",
    "# Data directories\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Search keywords for tech jobs\n",
    "TECH_KEYWORDS = [\n",
    "    'artificial intelligence',\n",
    "    'machine learning',\n",
    "    'data scientist',\n",
    "    'software engineer',\n",
    "    'ML engineer',\n",
    "    'AI engineer',\n",
    "    'deep learning',\n",
    "    'Python developer',\n",
    "    'data engineer',\n",
    "    'MLOps'\n",
    "]\n",
    "\n",
    "print(\"ğŸ”§ Configuration loaded\")\n",
    "print(f\"   API Endpoint: {BASE_URL}\")\n",
    "print(f\"   Rate limit: {60/REQUEST_DELAY:.0f} requests/min\")\n",
    "print(f\"   Target: {MAX_PAGES} pages Ã— {RESULTS_PER_PAGE} = {MAX_PAGES * RESULTS_PER_PAGE:,} jobs\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Configuration loaded\n",
      "   API Endpoint: https://api.adzuna.com/v1/api/jobs/us/search\n",
      "   Rate limit: 12 requests/min\n",
      "   Target: 100 pages Ã— 50 = 5,000 jobs\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Client Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:26:47.109467Z",
     "start_time": "2025-10-24T17:26:47.098311Z"
    }
   },
   "source": [
    "def fetch_jobs_page(page: int, keyword: str, max_retries: int = 3) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch one page of job listings from Adzuna API.\n",
    "    \n",
    "    Args:\n",
    "        page: Page number (1-indexed)\n",
    "        keyword: Search keyword\n",
    "        max_retries: Number of retry attempts on failure\n",
    "    \n",
    "    Returns:\n",
    "        JSON response dict or None on failure\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/{page}\"\n",
    "    \n",
    "    params = {\n",
    "        'app_id': APP_ID,\n",
    "        'app_key': APP_KEY,\n",
    "        'results_per_page': RESULTS_PER_PAGE,\n",
    "        'what': keyword,\n",
    "        'content-type': 'application/json',\n",
    "        'sort_by': 'date'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=15)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            \n",
    "            elif response.status_code == 429:\n",
    "                wait_time = (attempt + 1) * 10\n",
    "                print(f\"     Rate limit hit. Waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            \n",
    "            elif response.status_code == 403:\n",
    "                print(f\"    Authentication error (403). Check API credentials.\")\n",
    "                return None\n",
    "            \n",
    "            else:\n",
    "                print(f\"     HTTP {response.status_code}: {response.text[:100]}\")\n",
    "                return None\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"     Timeout (attempt {attempt + 1}/{max_retries})\")\n",
    "            time.sleep(5)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"    Request error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"    Failed after {max_retries} attempts\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_job_data(job: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Parse Adzuna job JSON into structured format.\n",
    "    Aligns schema with HackerNews data for consistency.\n",
    "    \"\"\"\n",
    "    description = job.get('description', '')\n",
    "    title = job.get('title', '')\n",
    "    \n",
    "    full_text = f\"{title} {description}\".lower()\n",
    "    \n",
    "    ai_keywords = [\n",
    "        'machine learning', 'ml engineer', 'ai engineer', 'artificial intelligence',\n",
    "        'deep learning', 'nlp', 'natural language', 'computer vision', 'llm',\n",
    "        'data scientist', 'pytorch', 'tensorflow', 'generative ai', 'gpt',\n",
    "        'neural network', 'transformers', 'reinforcement learning', 'mlops'\n",
    "    ]\n",
    "    has_ai_keywords = any(kw in full_text for kw in ai_keywords)\n",
    "    \n",
    "    remote_keywords = ['remote', 'work from home', 'wfh', 'distributed', 'anywhere', 'telecommute']\n",
    "    is_remote = any(kw in full_text for kw in remote_keywords)\n",
    "    \n",
    "    requires_python = 'python' in full_text\n",
    "    requires_js = any(x in full_text for x in ['javascript', 'typescript', 'react', 'node.js', 'angular', 'vue'])\n",
    "    \n",
    "    salary_min = job.get('salary_min', None)\n",
    "    salary_max = job.get('salary_max', None)\n",
    "    \n",
    "    if salary_min and salary_max:\n",
    "        salary = f\"${salary_min/1000:.0f}k-${salary_max/1000:.0f}k\"\n",
    "    elif salary_min:\n",
    "        salary = f\"${salary_min/1000:.0f}k+\"\n",
    "    elif salary_max:\n",
    "        salary = f\"up to ${salary_max/1000:.0f}k\"\n",
    "    else:\n",
    "        salary = \"Not specified\"\n",
    "    \n",
    "    location_data = job.get('location', {})\n",
    "    if isinstance(location_data, dict):\n",
    "        area = location_data.get('display_name', '')\n",
    "        location = area if area else \"Not specified\"\n",
    "    else:\n",
    "        location = str(location_data) if location_data else \"Not specified\"\n",
    "    \n",
    "    return {\n",
    "        'job_id': job.get('id', ''),\n",
    "        'company': job.get('company', {}).get('display_name', 'Not specified'),\n",
    "        'role': title,\n",
    "        'description': description[:1500],\n",
    "        'has_ai_keywords': has_ai_keywords,\n",
    "        'is_remote': is_remote,\n",
    "        'location': location,\n",
    "        'salary': salary,\n",
    "        'salary_min': salary_min,\n",
    "        'salary_max': salary_max,\n",
    "        'requires_python': requires_python,\n",
    "        'requires_js': requires_js,\n",
    "        'created_date': job.get('created', ''),\n",
    "        'redirect_url': job.get('redirect_url', ''),\n",
    "        'category': job.get('category', {}).get('label', '') if isinstance(job.get('category'), dict) else '',\n",
    "        'contract_type': job.get('contract_type', ''),\n",
    "        'text_length': len(description),\n",
    "        'source': 'adzuna',\n",
    "        'scraped_date': datetime.now().strftime('%Y-%m-%d')\n",
    "    }\n",
    "\n",
    "\n",
    "def filter_date_range(job: Dict, start_date: str = '2023-01-01', end_date: str = '2024-12-31') -> bool:\n",
    "    \"\"\"\n",
    "    Check if job posting is within target date range.\n",
    "    \"\"\"\n",
    "    created = job.get('created_date', '')\n",
    "    if not created:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        job_date = datetime.fromisoformat(created.replace('Z', '+00:00'))\n",
    "        start = datetime.fromisoformat(start_date)\n",
    "        end = datetime.fromisoformat(end_date)\n",
    "        return start <= job_date <= end\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "\n",
    "print(\" API client functions defined\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " API client functions defined\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Collection\n",
    "\n",
    "This will take approximately 8-10 minutes for 100 pages (5,000 jobs).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:38:04.057887Z",
     "start_time": "2025-10-24T17:27:29.240172Z"
    }
   },
   "source": [
    "def collect_jobs(keywords: List[str], max_pages_per_keyword: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Collect job postings for multiple keywords.\n",
    "    \n",
    "    Args:\n",
    "        keywords: List of search terms\n",
    "        max_pages_per_keyword: Max pages to fetch per keyword\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all collected jobs\n",
    "    \"\"\"\n",
    "    all_jobs = []\n",
    "    seen_ids = set()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" Starting Adzuna API Data Collection\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n Configuration:\")\n",
    "    print(f\"   Keywords: {len(keywords)}\")\n",
    "    print(f\"   Pages per keyword: {max_pages_per_keyword}\")\n",
    "    print(f\"   Max total jobs: ~{len(keywords) * max_pages_per_keyword * RESULTS_PER_PAGE:,}\")\n",
    "    print(f\"   Estimated time: {len(keywords) * max_pages_per_keyword * REQUEST_DELAY / 60:.1f} minutes\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for keyword_idx, keyword in enumerate(keywords, 1):\n",
    "        print(f\"\\n{'â”€'*70}\")\n",
    "        print(f\" Keyword {keyword_idx}/{len(keywords)}: '{keyword}'\")\n",
    "        print(f\"{'â”€'*70}\")\n",
    "        \n",
    "        keyword_jobs = 0\n",
    "        keyword_duplicates = 0\n",
    "        \n",
    "        for page in range(1, max_pages_per_keyword + 1):\n",
    "            print(f\"\\n    Page {page}/{max_pages_per_keyword}...\", end=' ')\n",
    "            \n",
    "            response = fetch_jobs_page(page, keyword)\n",
    "            \n",
    "            if not response:\n",
    "                print(\"Failed. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            results = response.get('results', [])\n",
    "            \n",
    "            if not results:\n",
    "                print(\"No more results. Moving to next keyword.\")\n",
    "                break\n",
    "            \n",
    "            page_jobs = 0\n",
    "            for job_raw in results:\n",
    "                job = parse_job_data(job_raw)\n",
    "                \n",
    "                if job['job_id'] in seen_ids:\n",
    "                    keyword_duplicates += 1\n",
    "                    continue\n",
    "                \n",
    "                if not filter_date_range(job):\n",
    "                    continue\n",
    "                \n",
    "                seen_ids.add(job['job_id'])\n",
    "                all_jobs.append(job)\n",
    "                page_jobs += 1\n",
    "                keyword_jobs += 1\n",
    "            \n",
    "            print(f\" {page_jobs} jobs (+{keyword_duplicates} dupes)\")\n",
    "            \n",
    "            if page % 10 == 0 and all_jobs:\n",
    "                checkpoint_df = pd.DataFrame(all_jobs)\n",
    "                checkpoint_df.to_csv(f'data/raw/adzuna_checkpoint_{len(all_jobs)}.csv', index=False)\n",
    "                print(f\"       Checkpoint saved: {len(all_jobs)} total jobs\")\n",
    "            \n",
    "            time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        print(f\"\\n   âœ¨ Keyword summary: {keyword_jobs} new jobs, {keyword_duplicates} duplicates\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" Collection Complete!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Total unique jobs: {len(all_jobs):,}\")\n",
    "    print(f\"   Time elapsed: {elapsed/60:.1f} minutes\")\n",
    "    print(f\"   Average rate: {len(all_jobs)/elapsed*60:.1f} jobs/minute\")\n",
    "    \n",
    "    return pd.DataFrame(all_jobs)\n",
    "\n",
    "\n",
    "df_adzuna = collect_jobs(TECH_KEYWORDS, max_pages_per_keyword=10)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " Starting Adzuna API Data Collection\n",
      "======================================================================\n",
      "\n",
      " Configuration:\n",
      "   Keywords: 10\n",
      "   Pages per keyword: 10\n",
      "   Max total jobs: ~5,000\n",
      "   Estimated time: 8.3 minutes\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 1/10: 'artificial intelligence'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 2/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 3/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 4/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 5/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 6/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 7/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 8/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 9/10...  50 jobs (+0 dupes)\n",
      "\n",
      "    Page 10/10...  50 jobs (+0 dupes)\n",
      "       Checkpoint saved: 500 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 500 new jobs, 0 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 2/10: 'machine learning'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  27 jobs (+23 dupes)\n",
      "\n",
      "    Page 2/10...  24 jobs (+49 dupes)\n",
      "\n",
      "    Page 3/10...  50 jobs (+49 dupes)\n",
      "\n",
      "    Page 4/10...  50 jobs (+49 dupes)\n",
      "\n",
      "    Page 5/10...  50 jobs (+49 dupes)\n",
      "\n",
      "    Page 6/10...  50 jobs (+49 dupes)\n",
      "\n",
      "    Page 7/10...  50 jobs (+49 dupes)\n",
      "\n",
      "    Page 8/10...  50 jobs (+49 dupes)\n",
      "\n",
      "    Page 9/10...  50 jobs (+49 dupes)\n",
      "\n",
      "    Page 10/10...  50 jobs (+49 dupes)\n",
      "       Checkpoint saved: 951 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 451 new jobs, 49 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 3/10: 'data scientist'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  25 jobs (+25 dupes)\n",
      "\n",
      "    Page 2/10...  34 jobs (+41 dupes)\n",
      "\n",
      "    Page 3/10...  28 jobs (+63 dupes)\n",
      "\n",
      "    Page 4/10...  30 jobs (+83 dupes)\n",
      "\n",
      "    Page 5/10...  50 jobs (+83 dupes)\n",
      "\n",
      "    Page 6/10...  50 jobs (+83 dupes)\n",
      "\n",
      "    Page 7/10...  50 jobs (+83 dupes)\n",
      "\n",
      "    Page 8/10...  50 jobs (+83 dupes)\n",
      "\n",
      "    Page 9/10...  50 jobs (+83 dupes)\n",
      "\n",
      "    Page 10/10...  50 jobs (+83 dupes)\n",
      "       Checkpoint saved: 1368 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 417 new jobs, 83 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 4/10: 'software engineer'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  38 jobs (+12 dupes)\n",
      "\n",
      "    Page 2/10...  39 jobs (+23 dupes)\n",
      "\n",
      "    Page 3/10...  36 jobs (+37 dupes)\n",
      "\n",
      "    Page 4/10...  37 jobs (+50 dupes)\n",
      "\n",
      "    Page 5/10...  41 jobs (+59 dupes)\n",
      "\n",
      "    Page 6/10...  45 jobs (+64 dupes)\n",
      "\n",
      "    Page 7/10...  45 jobs (+69 dupes)\n",
      "\n",
      "    Page 8/10...  40 jobs (+79 dupes)\n",
      "\n",
      "    Page 9/10...  38 jobs (+91 dupes)\n",
      "\n",
      "    Page 10/10...  41 jobs (+100 dupes)\n",
      "       Checkpoint saved: 1768 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 400 new jobs, 100 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 5/10: 'ML engineer'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  14 jobs (+36 dupes)\n",
      "\n",
      "    Page 2/10...  21 jobs (+65 dupes)\n",
      "\n",
      "    Page 3/10...  40 jobs (+75 dupes)\n",
      "\n",
      "    Page 4/10...  47 jobs (+78 dupes)\n",
      "\n",
      "    Page 5/10...  37 jobs (+91 dupes)\n",
      "\n",
      "    Page 6/10...  50 jobs (+91 dupes)\n",
      "\n",
      "    Page 7/10...  50 jobs (+91 dupes)\n",
      "\n",
      "    Page 8/10...  50 jobs (+91 dupes)\n",
      "\n",
      "    Page 9/10...  50 jobs (+91 dupes)\n",
      "\n",
      "    Page 10/10...  50 jobs (+91 dupes)\n",
      "       Checkpoint saved: 2177 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 409 new jobs, 91 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 6/10: 'AI engineer'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  17 jobs (+33 dupes)\n",
      "\n",
      "    Page 2/10...  18 jobs (+65 dupes)\n",
      "\n",
      "    Page 3/10...  16 jobs (+99 dupes)\n",
      "\n",
      "    Page 4/10...  28 jobs (+121 dupes)\n",
      "\n",
      "    Page 5/10...  22 jobs (+149 dupes)\n",
      "\n",
      "    Page 6/10...  34 jobs (+165 dupes)\n",
      "\n",
      "    Page 7/10...  32 jobs (+183 dupes)\n",
      "\n",
      "    Page 8/10...  34 jobs (+199 dupes)\n",
      "\n",
      "    Page 9/10...  26 jobs (+223 dupes)\n",
      "\n",
      "    Page 10/10...  30 jobs (+243 dupes)\n",
      "       Checkpoint saved: 2434 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 257 new jobs, 243 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 7/10: 'deep learning'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  6 jobs (+44 dupes)\n",
      "\n",
      "    Page 2/10...  19 jobs (+75 dupes)\n",
      "\n",
      "    Page 3/10...  25 jobs (+100 dupes)\n",
      "\n",
      "    Page 4/10...  30 jobs (+120 dupes)\n",
      "\n",
      "    Page 5/10...  28 jobs (+142 dupes)\n",
      "\n",
      "    Page 6/10...  29 jobs (+163 dupes)\n",
      "\n",
      "    Page 7/10...  28 jobs (+185 dupes)\n",
      "\n",
      "    Page 8/10...  31 jobs (+204 dupes)\n",
      "\n",
      "    Page 9/10...  29 jobs (+225 dupes)\n",
      "\n",
      "    Page 10/10...  41 jobs (+234 dupes)\n",
      "       Checkpoint saved: 2700 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 266 new jobs, 234 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 8/10: 'Python developer'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  11 jobs (+39 dupes)\n",
      "\n",
      "    Page 2/10...  33 jobs (+56 dupes)\n",
      "\n",
      "    Page 3/10...  37 jobs (+69 dupes)\n",
      "\n",
      "    Page 4/10...  36 jobs (+83 dupes)\n",
      "\n",
      "    Page 5/10...  38 jobs (+95 dupes)\n",
      "\n",
      "    Page 6/10...  35 jobs (+110 dupes)\n",
      "\n",
      "    Page 7/10...  30 jobs (+130 dupes)\n",
      "\n",
      "    Page 8/10...  31 jobs (+149 dupes)\n",
      "\n",
      "    Page 9/10...  42 jobs (+157 dupes)\n",
      "\n",
      "    Page 10/10...  41 jobs (+166 dupes)\n",
      "       Checkpoint saved: 3034 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 334 new jobs, 166 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 9/10: 'data engineer'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  24 jobs (+26 dupes)\n",
      "\n",
      "    Page 2/10...  21 jobs (+55 dupes)\n",
      "\n",
      "    Page 3/10...  17 jobs (+88 dupes)\n",
      "\n",
      "    Page 4/10...  30 jobs (+108 dupes)\n",
      "\n",
      "    Page 5/10...  25 jobs (+133 dupes)\n",
      "\n",
      "    Page 6/10...  21 jobs (+162 dupes)\n",
      "\n",
      "    Page 7/10...  31 jobs (+181 dupes)\n",
      "\n",
      "    Page 8/10...  32 jobs (+199 dupes)\n",
      "\n",
      "    Page 9/10...  39 jobs (+210 dupes)\n",
      "\n",
      "    Page 10/10...  33 jobs (+227 dupes)\n",
      "       Checkpoint saved: 3307 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 273 new jobs, 227 duplicates\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Keyword 10/10: 'MLOps'\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Page 1/10...  4 jobs (+46 dupes)\n",
      "\n",
      "    Page 2/10...  12 jobs (+84 dupes)\n",
      "\n",
      "    Page 3/10...  31 jobs (+103 dupes)\n",
      "\n",
      "    Page 4/10...  37 jobs (+116 dupes)\n",
      "\n",
      "    Page 5/10...  50 jobs (+116 dupes)\n",
      "\n",
      "    Page 6/10...  50 jobs (+116 dupes)\n",
      "\n",
      "    Page 7/10...  50 jobs (+116 dupes)\n",
      "\n",
      "    Page 8/10...  50 jobs (+116 dupes)\n",
      "\n",
      "    Page 9/10...  50 jobs (+116 dupes)\n",
      "\n",
      "    Page 10/10...  50 jobs (+116 dupes)\n",
      "       Checkpoint saved: 3691 total jobs\n",
      "\n",
      "   âœ¨ Keyword summary: 384 new jobs, 116 duplicates\n",
      "\n",
      "======================================================================\n",
      " Collection Complete!\n",
      "======================================================================\n",
      "   Total unique jobs: 3,691\n",
      "   Time elapsed: 10.6 minutes\n",
      "   Average rate: 348.9 jobs/minute\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality & Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:38:04.092988Z",
     "start_time": "2025-10-24T17:38:04.061378Z"
    }
   },
   "source": [
    "print(\"\\n DATA QUALITY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1ï¸  Dataset Overview:\")\n",
    "print(f\"   Total jobs collected: {len(df_adzuna):,}\")\n",
    "print(f\"   Unique companies: {df_adzuna['company'].nunique():,}\")\n",
    "print(f\"   Date range: {df_adzuna['created_date'].min()[:10]} to {df_adzuna['created_date'].max()[:10]}\")\n",
    "\n",
    "print(f\"\\n2ï¸  Data Completeness:\")\n",
    "print(f\"   Jobs with salary info: {(df_adzuna['salary_min'].notna().sum() / len(df_adzuna) * 100):.1f}%\")\n",
    "print(f\"   Jobs with location: {((df_adzuna['location'] != 'Not specified').sum() / len(df_adzuna) * 100):.1f}%\")\n",
    "print(f\"   Jobs with description: {(df_adzuna['text_length'] > 100).sum() / len(df_adzuna) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n3ï¸  AI/ML Content:\")\n",
    "ai_count = df_adzuna['has_ai_keywords'].sum()\n",
    "print(f\"   AI-related jobs: {ai_count:,} ({ai_count/len(df_adzuna)*100:.1f}%)\")\n",
    "print(f\"   Remote jobs: {df_adzuna['is_remote'].sum():,} ({df_adzuna['is_remote'].sum()/len(df_adzuna)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n4ï¸  Tech Stack Requirements:\")\n",
    "print(f\"   Python: {df_adzuna['requires_python'].sum():,} ({df_adzuna['requires_python'].sum()/len(df_adzuna)*100:.1f}%)\")\n",
    "print(f\"   JavaScript: {df_adzuna['requires_js'].sum():,} ({df_adzuna['requires_js'].sum()/len(df_adzuna)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n5ï¸  Salary Statistics:\")\n",
    "if df_adzuna['salary_min'].notna().any():\n",
    "    print(f\"   Median min salary: ${df_adzuna['salary_min'].median()/1000:.0f}k\")\n",
    "    print(f\"   Median max salary: ${df_adzuna['salary_max'].median()/1000:.0f}k\")\n",
    "    print(f\"   Avg salary range: ${df_adzuna['salary_min'].mean()/1000:.0f}k - ${df_adzuna['salary_max'].mean()/1000:.0f}k\")\n",
    "\n",
    "print(f\"\\n6ï¸  Top Hiring Companies:\")\n",
    "top_companies = df_adzuna['company'].value_counts().head(10)\n",
    "for company, count in top_companies.items():\n",
    "    print(f\"   {company[:40]}: {count} jobs\")\n",
    "\n",
    "print(f\"\\n7ï¸ Top Locations:\")\n",
    "top_locations = df_adzuna['location'].value_counts().head(10)\n",
    "for location, count in top_locations.items():\n",
    "    if location != \"Not specified\":\n",
    "        print(f\"   {location[:40]}: {count} jobs\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DATA QUALITY REPORT\n",
      "======================================================================\n",
      "\n",
      "1ï¸  Dataset Overview:\n",
      "   Total jobs collected: 3,691\n",
      "   Unique companies: 1,424\n",
      "   Date range: 2025-10-21 to 2025-10-24\n",
      "\n",
      "2ï¸  Data Completeness:\n",
      "   Jobs with salary info: 100.0%\n",
      "   Jobs with location: 100.0%\n",
      "   Jobs with description: 100.0%\n",
      "\n",
      "3ï¸  AI/ML Content:\n",
      "   AI-related jobs: 902 (24.4%)\n",
      "   Remote jobs: 465 (12.6%)\n",
      "\n",
      "4ï¸  Tech Stack Requirements:\n",
      "   Python: 97 (2.6%)\n",
      "   JavaScript: 21 (0.6%)\n",
      "\n",
      "5ï¸  Salary Statistics:\n",
      "   Median min salary: $125k\n",
      "   Median max salary: $134k\n",
      "   Avg salary range: $134k - $145k\n",
      "\n",
      "6ï¸  Top Hiring Companies:\n",
      "   Oracle: 278 jobs\n",
      "   Meta: 99 jobs\n",
      "   Deloitte: 92 jobs\n",
      "   Nelnet: 76 jobs\n",
      "   DELOITTE: 65 jobs\n",
      "   Contact Government Services, LLC: 51 jobs\n",
      "   Launch Potato: 51 jobs\n",
      "   Highmark Health: 50 jobs\n",
      "   BOEING: 49 jobs\n",
      "   Amazon: 48 jobs\n",
      "\n",
      "7ï¸ Top Locations:\n",
      "   US: 202 jobs\n",
      "   New York City, New York: 128 jobs\n",
      "   San Francisco, California: 95 jobs\n",
      "   Boston, Suffolk County: 66 jobs\n",
      "   Atlanta, Fulton County: 59 jobs\n",
      "   Chicago, Cook County: 56 jobs\n",
      "   Redmond, King County: 51 jobs\n",
      "   Austin, Travis County: 46 jobs\n",
      "   Los Angeles, Los Angeles County: 39 jobs\n",
      "   Grand Central, Manhattan: 38 jobs\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:38:23.448105Z",
     "start_time": "2025-10-24T17:38:23.391763Z"
    }
   },
   "source": [
    "output_file = 'data/raw/adzuna_jobs_2023_2024.csv'\n",
    "df_adzuna.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"\\n DATASET SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   File: {output_file}\")\n",
    "print(f\"   Size: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"   Records: {len(df_adzuna):,}\")\n",
    "print(f\"   Columns: {len(df_adzuna.columns)}\")\n",
    "\n",
    "print(f\"\\n Schema:\")\n",
    "print(df_adzuna.dtypes)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DATASET SAVED\n",
      "======================================================================\n",
      "   File: data/raw/adzuna_jobs_2023_2024.csv\n",
      "   Size: 2.83 MB\n",
      "   Records: 3,691\n",
      "   Columns: 19\n",
      "\n",
      " Schema:\n",
      "job_id              object\n",
      "company             object\n",
      "role                object\n",
      "description         object\n",
      "has_ai_keywords       bool\n",
      "is_remote             bool\n",
      "location            object\n",
      "salary              object\n",
      "salary_min         float64\n",
      "salary_max         float64\n",
      "requires_python       bool\n",
      "requires_js           bool\n",
      "created_date        object\n",
      "redirect_url        object\n",
      "category            object\n",
      "contract_type       object\n",
      "text_length          int64\n",
      "source              object\n",
      "scraped_date        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Data Preview\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:38:42.113748Z",
     "start_time": "2025-10-24T17:38:42.100244Z"
    }
   },
   "source": [
    "print(\"\\n SAMPLE JOB POSTINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ai_jobs = df_adzuna[df_adzuna['has_ai_keywords']].head(5)\n",
    "\n",
    "for idx, job in ai_jobs.iterrows():\n",
    "    remote = \" Remote\" if job['is_remote'] else \" Onsite\"\n",
    "    print(f\"\\n{'â”€'*70}\")\n",
    "    print(f\" {job['company']}\")\n",
    "    print(f\"   Role: {job['role'][:60]}\")\n",
    "    print(f\"   Location: {job['location'][:40]}\")\n",
    "    print(f\"   Salary: {job['salary']}\")\n",
    "    print(f\"   Type: {remote}\")\n",
    "    print(f\"   Posted: {job['created_date'][:10]}\")\n",
    "    print(f\"   Tech: {'Python' if job['requires_python'] else ''} {'JavaScript' if job['requires_js'] else ''}\")\n",
    "\n",
    "print(\"\\n\\n DataFrame Preview:\")\n",
    "df_adzuna[['company', 'role', 'location', 'salary', 'has_ai_keywords', 'is_remote']].head(10)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SAMPLE JOB POSTINGS\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " GoPuff\n",
      "   Role: Retail Sales Associate, Ballard\n",
      "   Location: Seattle, King County\n",
      "   Salary: $40k-$40k\n",
      "   Type:  Onsite\n",
      "   Posted: 2025-10-24\n",
      "   Tech:  \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Pryon\n",
      "   Role: Machine Learning Engineer - Modeling\n",
      "   Location: Washington, Washington, D.C.\n",
      "   Salary: $137k-$137k\n",
      "   Type:  Onsite\n",
      "   Posted: 2025-10-24\n",
      "   Tech:  \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Chef Robotics\n",
      "   Role: Senior Robotics Release and Test Engineer\n",
      "   Location: San Francisco, California\n",
      "   Salary: $164k-$164k\n",
      "   Type:  Onsite\n",
      "   Posted: 2025-10-24\n",
      "   Tech:  \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " SP+\n",
      "   Role: Hotel Valet Supervisor - Driving\n",
      "   Location: Roanoke, Roanoke County\n",
      "   Salary: $37k-$37k\n",
      "   Type:  Onsite\n",
      "   Posted: 2025-10-24\n",
      "   Tech:  \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " Vortexa\n",
      "   Role: Platform Engineer\n",
      "   Location: New York City, New York\n",
      "   Salary: $102k-$102k\n",
      "   Type:  Onsite\n",
      "   Posted: 2025-10-24\n",
      "   Tech:  \n",
      "\n",
      "\n",
      " DataFrame Preview:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             company  \\\n",
       "0                               Intermountain Health   \n",
       "1                               Intermountain Health   \n",
       "2                               Intermountain Health   \n",
       "3                               Intermountain Health   \n",
       "4                               Intermountain Health   \n",
       "5                               Intermountain Health   \n",
       "6                               Intermountain Health   \n",
       "7  Heart and Vascular - Denver - Intermountain He...   \n",
       "8                               Intermountain Health   \n",
       "9                               Intermountain Health   \n",
       "\n",
       "                                                role  \\\n",
       "0                  Director Nursing Peri-Op Services   \n",
       "1                            Angio Interventionalist   \n",
       "2                             Radiology Technologist   \n",
       "3                                   MRI Technologist   \n",
       "4                 Radiology Technologist Travel Team   \n",
       "5  Cardiovascular Technologist EP $15,000 Sign On...   \n",
       "6                         Registered Nurse Telemetry   \n",
       "7                Cardio-Thoracic Surgery - Physician   \n",
       "8                        CT Technologist Travel Team   \n",
       "9                                   MRI Technologist   \n",
       "\n",
       "                        location       salary  has_ai_keywords  is_remote  \n",
       "0  Wheat Ridge, Jefferson County  $159k-$159k            False      False  \n",
       "1               Glendale, Denver  $100k-$100k            False      False  \n",
       "2         Brighton, Adams County    $81k-$81k            False      False  \n",
       "3  Wheat Ridge, Jefferson County    $99k-$99k            False      False  \n",
       "4      Lafayette, Boulder County    $91k-$91k            False      False  \n",
       "5               Glendale, Denver    $65k-$65k            False      False  \n",
       "6      Lafayette, Boulder County  $124k-$124k            False      False  \n",
       "7               Glendale, Denver  $135k-$135k            False      False  \n",
       "8               Glendale, Denver    $98k-$98k            False      False  \n",
       "9              Boise, Ada County  $123k-$123k            False      False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>role</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>has_ai_keywords</th>\n",
       "      <th>is_remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>Director Nursing Peri-Op Services</td>\n",
       "      <td>Wheat Ridge, Jefferson County</td>\n",
       "      <td>$159k-$159k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>Angio Interventionalist</td>\n",
       "      <td>Glendale, Denver</td>\n",
       "      <td>$100k-$100k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>Radiology Technologist</td>\n",
       "      <td>Brighton, Adams County</td>\n",
       "      <td>$81k-$81k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>MRI Technologist</td>\n",
       "      <td>Wheat Ridge, Jefferson County</td>\n",
       "      <td>$99k-$99k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>Radiology Technologist Travel Team</td>\n",
       "      <td>Lafayette, Boulder County</td>\n",
       "      <td>$91k-$91k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>Cardiovascular Technologist EP $15,000 Sign On...</td>\n",
       "      <td>Glendale, Denver</td>\n",
       "      <td>$65k-$65k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>Registered Nurse Telemetry</td>\n",
       "      <td>Lafayette, Boulder County</td>\n",
       "      <td>$124k-$124k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Heart and Vascular - Denver - Intermountain He...</td>\n",
       "      <td>Cardio-Thoracic Surgery - Physician</td>\n",
       "      <td>Glendale, Denver</td>\n",
       "      <td>$135k-$135k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>CT Technologist Travel Team</td>\n",
       "      <td>Glendale, Denver</td>\n",
       "      <td>$98k-$98k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Intermountain Health</td>\n",
       "      <td>MRI Technologist</td>\n",
       "      <td>Boise, Ada County</td>\n",
       "      <td>$123k-$123k</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with HackerNews Data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T17:38:59.060976Z",
     "start_time": "2025-10-24T17:38:57.719742Z"
    }
   },
   "source": [
    "try:\n",
    "    df_hn = pd.read_csv('data/raw/hn_jobs_combined.csv')\n",
    "\n",
    "    print(\"\\n DATASET COMPARISON: Adzuna vs HackerNews\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'Total Jobs',\n",
    "            'AI/ML Jobs',\n",
    "            'AI/ML Percentage',\n",
    "            'Remote Jobs',\n",
    "            'Remote Percentage',\n",
    "            'Python Required',\n",
    "            'JavaScript Required'\n",
    "        ],\n",
    "        'Adzuna': [\n",
    "            f\"{len(df_adzuna):,}\",\n",
    "            f\"{df_adzuna['has_ai_keywords'].sum():,}\",\n",
    "            f\"{df_adzuna['has_ai_keywords'].sum()/len(df_adzuna)*100:.1f}%\",\n",
    "            f\"{df_adzuna['is_remote'].sum():,}\",\n",
    "            f\"{df_adzuna['is_remote'].sum()/len(df_adzuna)*100:.1f}%\",\n",
    "            f\"{df_adzuna['requires_python'].sum():,}\",\n",
    "            f\"{df_adzuna['requires_js'].sum():,}\"\n",
    "        ],\n",
    "        'HackerNews': [\n",
    "            f\"{len(df_hn):,}\",\n",
    "            f\"{df_hn['has_ai_keywords'].sum():,}\",\n",
    "            f\"{df_hn['has_ai_keywords'].sum()/len(df_hn)*100:.1f}%\",\n",
    "            f\"{df_hn['is_remote'].sum():,}\",\n",
    "            f\"{df_hn['is_remote'].sum()/len(df_hn)*100:.1f}%\",\n",
    "            f\"{df_hn['requires_python'].sum():,}\",\n",
    "            f\"{df_hn['requires_js'].sum():,}\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n Key Insights:\")\n",
    "    print(f\"   â€¢ Adzuna provides {len(df_adzuna)/len(df_hn):.1f}x more data than HN\")\n",
    "    print(f\"   â€¢ Adzuna has more structured salary data\")\n",
    "    print(f\"   â€¢ Combined dataset: {len(df_adzuna) + len(df_hn):,} total job postings\")\n",
    "    print(f\"   â€¢ Broader validation dataset for trend analysis\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\n  HN data not found for comparison\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DATASET COMPARISON: Adzuna vs HackerNews\n",
      "======================================================================\n",
      "             Metric Adzuna HackerNews\n",
      "         Total Jobs  3,691        711\n",
      "         AI/ML Jobs    902        161\n",
      "   AI/ML Percentage  24.4%      22.6%\n",
      "        Remote Jobs    465        430\n",
      "  Remote Percentage  12.6%      60.5%\n",
      "    Python Required     97        151\n",
      "JavaScript Required     21        241\n",
      "\n",
      " Key Insights:\n",
      "   â€¢ Adzuna provides 5.2x more data than HN\n",
      "   â€¢ Adzuna has more structured salary data\n",
      "   â€¢ Combined dataset: 4,402 total job postings\n",
      "   â€¢ Broader validation dataset for trend analysis\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
